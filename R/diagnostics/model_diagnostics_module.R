# Model Diagnostics Module

library(shiny)
library(ggplot2)
library(plotly)
library(DT)
library(corrplot)
library(car)

#' UI function for model diagnostics module
#'
#' @param id The namespace id for the module
#' @return A UI element
#' @export
model_diagnostics_UI <- function(id) {
  ns <- NS(id)
  
  tagList(
    h3("Advanced Model Diagnostics"),
    p("Comprehensive analysis and validation of your trained model."),
    
    conditionalPanel(
      condition = "false", # Will be updated by server when model is available
      ns = ns,
      
      fluidRow(
        column(4,
               wellPanel(
                 h4("Model Summary"),
                 verbatimTextOutput(ns("model_info")),
                 
                 hr(),
                 
                 h4("Performance Metrics"),
                 verbatimTextOutput(ns("performance_summary")),
                 
                 hr(),
                 
                 h4("Diagnostic Options"),
                 checkboxGroupInput(ns("diagnostic_tests"), 
                                  "Select Diagnostic Tests:",
                                  choices = list(
                                    "Residual Analysis" = "residuals",
                                    "Normality Tests" = "normality",
                                    "Homoscedasticity" = "homoscedasticity",
                                    "Autocorrelation" = "autocorrelation",
                                    "Outlier Detection" = "outliers",
                                    "Cross-Validation" = "cv",
                                    "Bootstrap Analysis" = "bootstrap"
                                  ),
                                  selected = c("residuals", "normality", "outliers")),
                 
                 actionButton(ns("run_diagnostics"), "Run Selected Diagnostics", 
                            class = "btn-primary"),
                 
                 hr(),
                 
                 downloadButton(ns("download_report"), "Download Diagnostic Report", 
                              class = "btn-success")
               )
        ),
        
        column(8,
               tabsetPanel(id = ns("diagnostic_tabs"),
                 tabPanel("Model Validation",
                          h4("Cross-Validation Results"),
                          plotlyOutput(ns("cv_plot")),
                          
                          h4("Learning Curves"),
                          plotlyOutput(ns("learning_curve"))
                 ),
                 
                 tabPanel("Residual Analysis",
                          fluidRow(
                            column(6, plotlyOutput(ns("residuals_vs_fitted"))),
                            column(6, plotlyOutput(ns("residuals_histogram")))
                          ),
                          fluidRow(
                            column(6, plotlyOutput(ns("qq_plot"))),
                            column(6, plotlyOutput(ns("scale_location_plot")))
                          )
                 ),
                 
                 tabPanel("Outlier Detection",
                          h4("Outlier Analysis"),
                          DTOutput(ns("outliers_table")),
                          
                          h4("Leverage vs Residuals"),
                          plotlyOutput(ns("leverage_plot")),
                          
                          h4("Cook's Distance"),
                          plotlyOutput(ns("cooks_distance_plot"))
                 ),
                 
                 tabPanel("Statistical Tests",
                          h4("Diagnostic Test Results"),
                          verbatimTextOutput(ns("statistical_tests")),
                          
                          h4("Assumptions Validation"),
                          DTOutput(ns("assumptions_table"))
                 ),
                 
                 tabPanel("Feature Analysis",
                          h4("Feature Correlations"),
                          plotOutput(ns("correlation_plot")),
                          
                          h4("Partial Dependence Plots"),
                          uiOutput(ns("pdp_plots"))
                 ),
                 
                 tabPanel("Model Comparison",
                          h4("Model Comparison Metrics"),
                          DTOutput(ns("model_comparison_table")),
                          
                          h4("Performance Comparison"),
                          plotlyOutput(ns("performance_comparison_plot"))
                 )
               )
        )
      )
    ),
    
    # Show message when no model is available
    conditionalPanel(
      condition = "true", # Will be updated by server
      ns = ns,
      div(class = "alert alert-info",
          h4("No Model Available"),
          p("Please complete the model training step to access advanced diagnostics."),
          p("Once you have trained a model, this section will provide comprehensive diagnostic tools including:"),
          tags$ul(
            tags$li("Residual analysis and assumption testing"),
            tags$li("Cross-validation and bootstrap analysis"),
            tags$li("Outlier and influence point detection"),
            tags$li("Feature importance and partial dependence plots"),
            tags$li("Model comparison and performance metrics"),
            tags$li("Downloadable diagnostic reports")
          )
      )
    )
  )
}

# Server logic for model diagnostics
model_diagnostics_server <- function(input, output, session, model, data, target_column) {
  observeEvent(input$run_diagnostics, {
    diagnostics <- generate_model_diagnostics(model, data, target_column)
    
    output$diagnostics_summary <- renderPrint({
      cat("RMSE:", diagnostics$rmse, "\n")
      cat("R-squared:", diagnostics$r_squared, "\n")
    })
    
    output$residuals_plot <- renderPlot({
      diagnostics$plots$residuals_plot
    })
    
    output$qq_plot <- renderPlot({
      diagnostics$plots$qq_plot
    })
  })
}

#' Server function for model diagnostics module
#'
#' @param id The namespace id for the module
#' @param trained_model Reactive expression from the model training module
#' @return A reactive expression containing diagnostic results
#' @export
model_diagnostics_Server <- function(id, trained_model) {
  moduleServer(id, function(input, output, session) {
    
    ns <- session$ns
    
    # Reactive values to store diagnostic results
    diagnostic_results <- reactiveVal(NULL)
    
    # Check if model is available and update UI visibility
    observe({
      has_model <- !is.null(trained_model()) && !is.null(trained_model()$model)
      
      # Toggle visibility of diagnostic panels
      shinyjs::toggle("diagnostic_tabs", condition = has_model)
      shinyjs::toggle("model_info", condition = has_model)
    })
    
    # Display model information
    output$model_info <- renderPrint({
      req(trained_model())
      
      model_data <- trained_model()
      
      cat("Model Type:", model_data$model_name, "\n")
      cat("Problem Type:", model_data$problem_type, "\n")
      cat("Target Variable:", model_data$target_column, "\n")
      cat("Number of Predictors:", length(model_data$predictor_columns), "\n")
      cat("Number of Observations:", length(model_data$actual), "\n")
    })
    
    # Display performance summary
    output$performance_summary <- renderPrint({
      req(trained_model())
      
      perf <- trained_model()$performance
      cat("Performance Metrics:\n\n")
      
      for (metric in names(perf)) {
        cat(metric, ":", round(perf[[metric]], 4), "\n")
      }
    })
    
    # Run diagnostics when button is clicked
    observeEvent(input$run_diagnostics, {
      req(trained_model(), input$diagnostic_tests)
      
      withProgress(message = "Running diagnostic tests...", value = 0.1, {
        
        model_data <- trained_model()
        actual <- model_data$actual
        predicted <- model_data$predictions
        residuals <- actual - predicted
        
        # Initialize diagnostic results
        results <- list()
        
        if ("residuals" %in% input$diagnostic_tests) {
          incProgress(0.1, detail = "Analyzing residuals")
          results$residuals <- analyze_residuals(actual, predicted, residuals)
        }
        
        if ("normality" %in% input$diagnostic_tests) {
          incProgress(0.1, detail = "Testing normality")
          results$normality <- test_normality(residuals)
        }
        
        if ("homoscedasticity" %in% input$diagnostic_tests) {
          incProgress(0.1, detail = "Testing homoscedasticity")
          results$homoscedasticity <- test_homoscedasticity(predicted, residuals)
        }
        
        if ("outliers" %in% input$diagnostic_tests) {
          incProgress(0.1, detail = "Detecting outliers")
          results$outliers <- detect_outliers(actual, predicted, residuals)
        }
        
        if ("cv" %in% input$diagnostic_tests) {
          incProgress(0.1, detail = "Running cross-validation")
          results$cv <- run_cross_validation(model_data)
        }
        
        if ("bootstrap" %in% input$diagnostic_tests) {
          incProgress(0.1, detail = "Bootstrap analysis")
          results$bootstrap <- run_bootstrap_analysis(model_data)
        }
        
        diagnostic_results(results)
        update_diagnostic_outputs()
        
        showNotification("Diagnostic tests completed", type = "message")
      })
    })
    
    # Update diagnostic outputs
    update_diagnostic_outputs <- function() {
      req(diagnostic_results(), trained_model())
      
      results <- diagnostic_results()
      model_data <- trained_model()
      actual <- model_data$actual
      predicted <- model_data$predictions
      residuals <- actual - predicted
      
      # Residuals vs Fitted plot
      output$residuals_vs_fitted <- renderPlotly({
        df <- data.frame(Fitted = predicted, Residuals = residuals)
        
        p <- plot_ly(df, x = ~Fitted, y = ~Residuals, type = "scatter", mode = "markers",
                  marker = list(size = 8, opacity = 0.6, color = "blue")) %>%
          add_trace(x = range(predicted), y = c(0, 0), type = "scatter", mode = "lines",
                  line = list(color = "red", dash = "dash"), showlegend = FALSE) %>%
          layout(title = "Residuals vs Fitted Values",
                xaxis = list(title = "Fitted Values"),
                yaxis = list(title = "Residuals"),
                hovermode = "closest")
        
        p
      })
      
      # Residuals histogram
      output$residuals_histogram <- renderPlotly({
        p <- plot_ly(x = residuals, type = "histogram", 
                  marker = list(color = "steelblue", line = list(color = "white", width = 0.2))) %>%
          layout(title = "Distribution of Residuals",
                xaxis = list(title = "Residuals"),
                yaxis = list(title = "Frequency"))
        
        p
      })
      
      # Q-Q plot
      output$qq_plot <- renderPlotly({
        # Calculate theoretical quantiles
        n <- length(residuals)
        theoretical <- qnorm((1:n - 0.5) / n)
        sample_quantiles <- sort(residuals)
        
        df <- data.frame(Theoretical = theoretical, Sample = sample_quantiles)
        
        p <- plot_ly(df, x = ~Theoretical, y = ~Sample, type = "scatter", mode = "markers",
                  marker = list(size = 8, opacity = 0.6, color = "blue")) %>%
          add_trace(x = range(theoretical), y = range(theoretical), type = "scatter", mode = "lines",
                  line = list(color = "red"), showlegend = FALSE) %>%
          layout(title = "Q-Q Plot of Residuals",
                xaxis = list(title = "Theoretical Quantiles"),
                yaxis = list(title = "Sample Quantiles"),
                hovermode = "closest")
        
        p
      })
      
      # Scale-Location plot
      output$scale_location_plot <- renderPlotly({
        sqrt_abs_residuals <- sqrt(abs(residuals))
        df <- data.frame(Fitted = predicted, SqrtAbsResiduals = sqrt_abs_residuals)
        
        p <- plot_ly(df, x = ~Fitted, y = ~SqrtAbsResiduals, type = "scatter", mode = "markers",
                  marker = list(size = 8, opacity = 0.6, color = "blue")) %>%
          layout(title = "Scale-Location Plot",
                xaxis = list(title = "Fitted Values"),
                yaxis = list(title = "âˆš|Residuals|"),
                hovermode = "closest")
        
        p
      })
      
      # Statistical tests output
      output$statistical_tests <- renderPrint({
        if ("normality" %in% names(results)) {
          cat("=== NORMALITY TESTS ===\n")
          cat("Shapiro-Wilk Test p-value:", round(results$normality$shapiro_pvalue, 4), "\n")
          cat("Interpretation:", ifelse(results$normality$shapiro_pvalue > 0.05, 
                                     "Residuals appear normal", 
                                     "Residuals may not be normal"), "\n\n")
        }
        
        if ("homoscedasticity" %in% names(results)) {
          cat("=== HOMOSCEDASTICITY TESTS ===\n")
          cat("Breusch-Pagan Test p-value:", round(results$homoscedasticity$bp_pvalue, 4), "\n")
          cat("Interpretation:", ifelse(results$homoscedasticity$bp_pvalue > 0.05, 
                                     "Homoscedasticity assumption met", 
                                     "Heteroscedasticity detected"), "\n\n")
        }
      })
      
      # Outliers table
      if ("outliers" %in% names(results)) {
        output$outliers_table <- renderDT({
          datatable(results$outliers$outlier_table, 
                   options = list(pageLength = 10, scrollX = TRUE))
        })
        
        # Cook's distance plot
        output$cooks_distance_plot <- renderPlotly({
          cooks_d <- results$outliers$cooks_distance
          obs_index <- 1:length(cooks_d)
          
          df <- data.frame(Index = obs_index, CooksDistance = cooks_d)
          
          p <- plot_ly(df, x = ~Index, y = ~CooksDistance, type = "scatter", mode = "markers",
                    marker = list(size = 8, opacity = 0.6, color = "blue")) %>%
            add_trace(x = range(obs_index), y = c(4/length(cooks_d), 4/length(cooks_d)), 
                    type = "scatter", mode = "lines",
                    line = list(color = "red", dash = "dash"), showlegend = FALSE) %>%
            layout(title = "Cook's Distance",
                  xaxis = list(title = "Observation Index"),
                  yaxis = list(title = "Cook's Distance"),
                  hovermode = "closest")
          
          p
        })
      }
      
      # Cross-validation plot
      if ("cv" %in% names(results)) {
        output$cv_plot <- renderPlotly({
          cv_results <- results$cv
          
          p <- plot_ly(x = 1:length(cv_results$scores), y = cv_results$scores, 
                    type = "scatter", mode = "lines+markers",
                    line = list(color = "blue"), marker = list(size = 8)) %>%
            add_trace(x = c(1, length(cv_results$scores)), 
                    y = c(mean(cv_results$scores), mean(cv_results$scores)),
                    type = "scatter", mode = "lines",
                    line = list(color = "red", dash = "dash"), showlegend = FALSE) %>%
            layout(title = paste("Cross-Validation Scores (Mean:", round(mean(cv_results$scores), 3), ")"),
                  xaxis = list(title = "Fold"),
                  yaxis = list(title = "Score"),
                  hovermode = "closest")
          
          p
        })
      }
    }
    
    # Helper functions for diagnostic tests
    analyze_residuals <- function(actual, predicted, residuals) {
      list(
        mean_residual = mean(residuals),
        std_residual = sd(residuals),
        max_residual = max(abs(residuals)),
        residual_range = range(residuals)
      )
    }
    
    test_normality <- function(residuals) {
      shapiro_test <- tryCatch({
        shapiro.test(residuals)$p.value
      }, error = function(e) {
        # If sample too large for Shapiro-Wilk, use alternative
        ks.test(residuals, "pnorm", mean(residuals), sd(residuals))$p.value
      })
      
      list(shapiro_pvalue = shapiro_test)
    }
    
    test_homoscedasticity <- function(predicted, residuals) {
      # Simple Breusch-Pagan test approximation
      # In a real app, use the lmtest package
      bp_stat <- cor(predicted, residuals^2)^2 * length(residuals)
      bp_pvalue <- 1 - pchisq(bp_stat, df = 1)
      
      list(bp_pvalue = bp_pvalue)
    }
    
    detect_outliers <- function(actual, predicted, residuals) {
      # Calculate standardized residuals
      std_residuals <- residuals / sd(residuals)
      
      # Calculate leverage (simplified)
      leverage <- rep(2/length(actual), length(actual))  # Simplified calculation
      
      # Calculate Cook's distance (simplified)
      cooks_d <- (std_residuals^2 * leverage) / (2 * (1 - leverage)^2)
      
      # Identify outliers
      outlier_threshold <- 4/length(actual)
      outliers <- which(cooks_d > outlier_threshold)
      
      outlier_table <- data.frame(
        Index = outliers,
        Actual = actual[outliers],
        Predicted = predicted[outliers],
        Residual = residuals[outliers],
        CooksDistance = cooks_d[outliers]
      )
      
      list(
        outlier_table = outlier_table,
        cooks_distance = cooks_d,
        leverage = leverage
      )
    }
    
    run_cross_validation <- function(model_data) {
      # Simplified CV simulation - in real app, use actual CV
      set.seed(123)
      cv_scores <- rnorm(5, mean = 0.8, sd = 0.05)
      cv_scores <- pmax(cv_scores, 0)  # Ensure positive scores
      
      list(scores = cv_scores)
    }
    
    run_bootstrap_analysis <- function(model_data) {
      # Simplified bootstrap - in real app, implement actual bootstrap
      set.seed(123)
      bootstrap_estimates <- rnorm(100, mean = 0.8, sd = 0.02)
      
      list(
        estimates = bootstrap_estimates,
        ci_lower = quantile(bootstrap_estimates, 0.025),
        ci_upper = quantile(bootstrap_estimates, 0.975)
      )
    }
    
    # Download diagnostic report
    output$download_report <- downloadHandler(
      filename = function() {
        paste("model_diagnostics_report_", Sys.Date(), ".html", sep = "")
      },
      content = function(file) {
        # In a real app, generate an HTML report with all diagnostics
        # For now, create a simple text summary
        
        req(trained_model(), diagnostic_results())
        
        model_data <- trained_model()
        results <- diagnostic_results()
        
        report_content <- paste(
          "MODEL DIAGNOSTICS REPORT",
          "========================",
          "",
          paste("Generated on:", Sys.time()),
          paste("Model Type:", model_data$model_name),
          paste("Problem Type:", model_data$problem_type),
          paste("Target Variable:", model_data$target_column),
          "",
          "PERFORMANCE METRICS:",
          paste(names(model_data$performance), ":", sapply(model_data$performance, round, 4), collapse = "\n"),
          "",
          "DIAGNOSTIC TESTS SUMMARY:",
          "See attached plots and detailed analysis in the application.",
          "",
          sep = "\n"
        )
        
        writeLines(report_content, file)
      }
    )
    
    return(diagnostic_results)
  })
}